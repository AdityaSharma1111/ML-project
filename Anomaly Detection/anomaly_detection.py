# -*- coding: utf-8 -*-
"""Anomaly Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c_iMNFQXj4bdiBhyCL9FJ_oAgipGdQPt
"""

import numpy as np
import matplotlib.pyplot as plt


def load_data_multi():
    X = np.load("/content/X_part2.npy")
    X_val = np.load("/content/X_val_part2.npy")
    y_val = np.load("/content/y_val_part2.npy")
    return X, X_val, y_val


def multivariate_gaussian(X, mu, var):

    k = len(mu)

    if var.ndim == 1:
        var = np.diag(var)

    X = X - mu
    p = (2* np.pi)**(-k/2) * np.linalg.det(var)**(-0.5) * \
        np.exp(-0.5 * np.sum(np.matmul(X, np.linalg.pinv(var)) * X, axis=1))

    return p

# load the dataset
X_train_high, X_val_high, y_val_high = load_data_multi()

print ('The shape of X_train_high is:', X_train_high.shape)
print ('The shape of X_val_high is:', X_val_high.shape)
print ('The shape of y_val_high is: ', y_val_high.shape)

def estimate_gaussian(X):
    #Calculates mean and variance of all features in the dataset
    m, n = X.shape

    mu = 1 / m * np.sum(X, axis = 0)
    var = 1 / m * np.sum((X - mu) ** 2, axis = 0)

    return mu, var

def select_threshold(y_val, p_val):
    """
    Finds the best threshold to use for selecting outliers
    based on the results from a validation set (p_val)
    and the ground truth (y_val)

    Args:
        y_val (ndarray): Ground truth on validation set
        p_val (ndarray): Results on validation set

    Returns:
        epsilon (float): Threshold chosen
        F1 (float):      F1 score by choosing epsilon as threshold
    """

    best_epsilon = 0
    best_F1 = 0
    F1 = 0

    step_size = (max(p_val) - min(p_val)) / 1000

    for epsilon in np.arange(min(p_val), max(p_val), step_size):

        predictions = (p_val < epsilon)
        tp = np.sum((predictions == 1) & (y_val == 1))
        fn = np.sum((predictions == 0) & (y_val == 1))
        fp = sum((predictions == 1) & (y_val == 0))

        if(tp + fp == 0):
          prec = 0
          rec = 0
          F1 = 0
        else:
          prec = tp / (tp + fp)
          rec = tp / (tp + fn)
          F1 = 2 * prec * rec / (prec + rec)

        if F1 > best_F1:
            best_F1 = F1
            best_epsilon = epsilon

    return best_epsilon, best_F1

def evaluate_model(X_val, y_val, mu, var, best_epsilon):
    # Calculate the probability of each validation example
    p_val = multivariate_gaussian(X_val, mu, var)

    # Predict anomalies using the best epsilon
    predictions = (p_val <= best_epsilon).astype(int)

    # Calculate TP, FP, TN, and FN
    tp = np.sum((predictions == 1) & (y_val == 1))
    fp = np.sum((predictions == 1) & (y_val == 0))
    tn = np.sum((predictions == 0) & (y_val == 0))
    fn = np.sum((predictions == 0) & (y_val == 1))

    # Calculate metrics
    accuracy = (tp + tn) / (tp + fp + tn + fn)
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

    return accuracy, precision, recall, f1_score

# Estimate the Gaussian parameters
mu_high, var_high = estimate_gaussian(X_train_high)

# Evaluate the probabilites for the training set
p_high = multivariate_gaussian(X_train_high, mu_high, var_high)

# Evaluate the probabilites for the cross validation set
p_val_high = multivariate_gaussian(X_val_high, mu_high, var_high)

# Find the best threshold
epsilon_high, F1_high = select_threshold(y_val_high, p_val_high)

print('Best epsilon found using cross-validation: %e'% epsilon_high)
print('Best F1 on Cross Validation Set:  %f'% F1_high)
print('# Anomalies found: %d'% sum(p_high < epsilon_high))

mu, var = estimate_gaussian(X_train_high)
accuracy, precision, recall, f1_score = evaluate_model(X_val_high, y_val_high, mu, var, epsilon_high)

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1_score)